import pickle
import os
import logging
from logging.handlers import RotatingFileHandler
import argparse


# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
LOG_FILE = os.path.join(LOG_DIR, "test_output.log")
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    handlers=[
        RotatingFileHandler(LOG_FILE, maxBytes=1024 * 1024 * 5, backupCount=5, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("PickleViewer")


def view_pickle_file(filepath):
    """
    æŸ¥çœ‹ .pkl æ–‡ä»¶å†…å®¹ï¼Œé€‚é… collect_multi_thread.py çš„æ ¼å¼ã€‚
    æ”¯æŒï¼š
      - å•ä¸ªæ ·æœ¬ï¼ˆtupleï¼‰
      - å­—å…¸ç»“æ„ {'data_buffer': list/deque, 'iters': int}
    """
    if not os.path.exists(filepath):
        logger.error(f"âŒ æ–‡ä»¶ {filepath} ä¸å­˜åœ¨")
        return

    logger.info(f"\nğŸ“„ æ­£åœ¨æŸ¥çœ‹æ–‡ä»¶: {filepath}")

    try:
        with open(filepath, 'rb') as f:
            idx = 0
            while True:
                try:
                    obj = pickle.load(f)

                    logger.info(f"\nğŸ“¦ å¯¹è±¡ #{idx}:")
                    logger.info(f"Type: {type(obj)}")

                    if isinstance(obj, dict):
                        keys = list(obj.keys())
                        logger.info(f"Keys: {keys}")

                        if 'data_buffer' in obj:
                            data_len = len(obj['data_buffer'])
                            logger.info(f"DataBuffer length: {data_len}")
                        if 'iters' in obj:
                            logger.info(f"Iterations: {obj['iters']}")

                        if 'data_buffer' in obj and len(obj['data_buffer']) > 0:
                            sample = obj['data_buffer'][0]
                            logger.info(f"First Sample:\n{str(sample)[:500]}...")

                    else:
                        logger.info(f"Raw Data (length {len(obj) if hasattr(obj, '__len__') else '?'}):\n{str(obj)[:500]}...")

                    idx += 1
                except EOFError as e:
                    break
        logger.info(f"\nâœ… å…±è¯»å–åˆ° {idx} ä¸ªå¯¹è±¡ã€‚")
    except Exception as e:
        logger.error(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")


def scan_and_view_all_pkl_files(directory="data"):
    """
    æ‰«ææŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰çš„ .pkl æ–‡ä»¶å¹¶è°ƒç”¨ view_pickle_file æŸ¥çœ‹
    """
    if not os.path.exists(directory):
        logger.error(f"âŒ ç›®å½• {directory} ä¸å­˜åœ¨")
        return

    logger.info(f"\nğŸ” å¼€å§‹æ‰«æç›®å½•: {directory}")
    pkl_files = [f for f in os.listdir(directory) if f.endswith('.pkl')]

    if not pkl_files:
        logger.warning(f"âš ï¸ åœ¨ {directory} ä¸­æœªæ‰¾åˆ°ä»»ä½• .pkl æ–‡ä»¶")
        return

    logger.info(f"ğŸ“‚ æ‰¾åˆ° {len(pkl_files)} ä¸ª .pkl æ–‡ä»¶:")
    for filename in pkl_files:
        filepath = os.path.join(directory, filename)
        logger.info(f"ğŸ” æ­£åœ¨å¤„ç†æ–‡ä»¶: {filename}")
        view_pickle_file(filepath)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æŸ¥çœ‹ .pkl æ–‡ä»¶å†…å®¹")
    group = parser.add_mutually_exclusive_group(required=False)
    group.add_argument("--file", type=str,default="data/train_data_buffer.pkl", help="æŒ‡å®šè¦æŸ¥çœ‹çš„ .pkl æ–‡ä»¶è·¯å¾„")
    # group.add_argument("--dir", type=str, default="data", help="æŒ‡å®šè¦æ‰«æçš„ç›®å½•ï¼Œé»˜è®¤ä¸º data/")
    args = parser.parse_args()

    if args.file:
        view_pickle_file(args.file)
    # if args.dir:
    #     scan_and_view_all_pkl_files(args.dir)
    else:
        scan_and_view_all_pkl_files("data")  # é»˜è®¤æ‰«æ data/
